{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Recall from the first homework the dataset from \"X-RAY STAR CLUSTERS IN THE CARINA COMPLEX\" Feigelson et al.\n",
    "\n",
    "Their methodology works as follows:\n",
    "1. They first use a density estimator to get a function $f : \\mathbb{R^2} \\to \\mathbb{R}$.\n",
    "2. Then, they consider the suplevel sets of $f$. That is, they find a suitable density threshold $\\lambda > 0 \\in \\mathbb{R}$ and the set $S_\\lambda = \\{x \\in \\mathbb{R}^2 : f(x) \\geq \\lambda\\}$.\n",
    "3. Finally, they take as clusters the connected components of $S_\\lambda$.\n",
    "\n",
    "The choice of $\\lambda$ is explained and justified in the paper."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "1. Write down a function in Python that, given a point cloud $X \\subseteq \\mathbb{R}^2$, it clusters it using the procedure above.\n",
    "To do this, you can use the functions defined below.\n",
    "2. Describe the inputs and output of your procedure.\n",
    "Can you take as input just a point cloud or do you require extra parameters?\n",
    "3. Use that function to try to get a clustering similar to that of the paper mentioned above.\n",
    "4. Can you think of a topological summary similar to that of Persistable that would be useful for choosing the parameters of your function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports and plotting functionality\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# this library gives an easy way to create color palettes with\n",
    "# very different colors. This is useful for coloring clusterings.\n",
    "import glasbey\n",
    "\n",
    "# a simple wrapper for glasbey\n",
    "def cluster_colors(n_classes):\n",
    "    return np.array(glasbey.create_palette(palette_size=n_classes))\n",
    "\n",
    "# a function that will plot a 2D dataset and, optionally, color it according\n",
    "# to a user given clustering. If no clustering is given, all data points are\n",
    "# colored with the same color.\n",
    "# Moreover, the cluster label is allowed to be -1. In that case the point is\n",
    "# considered \"unclustered\" and is colored in gray\n",
    "def plot_clustering(X, clustering = None, limits=None, sizes=[4, 2], noise_points=True, axis=True):\n",
    "    if clustering is None:\n",
    "        clustering = np.ones(X.shape[0], dtype=int)\n",
    "    X_clustered = X[clustering != -1]\n",
    "    X_unclustered = X[clustering == -1]\n",
    "    clustering_clustered = clustering[clustering != -1]\n",
    "    if noise_points:\n",
    "        plt.scatter(\n",
    "            X_unclustered[:, 0],\n",
    "            X_unclustered[:, 1],\n",
    "            s=sizes[1],\n",
    "            c=\"grey\",\n",
    "        )\n",
    "    plt.scatter(\n",
    "        X_clustered[:, 0],\n",
    "        X_clustered[:, 1],\n",
    "        s=sizes[0],\n",
    "        c=cluster_colors(max(clustering) + 1)[clustering_clustered],\n",
    "    )\n",
    "    if limits is not None:\n",
    "        plt.xlim([limits[0],limits[1]])\n",
    "        plt.ylim([limits[2],limits[3]])\n",
    "    if not axis:\n",
    "        plt.axis(\"Off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute connected components of graph and kernel density estimator\n",
    "\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def graph_connected_components(n_vertices, edges):\n",
    "    \"\"\" Label vertices of a graph by their connected component.\n",
    "    \n",
    "    n_vertices: int\n",
    "        The number of vertices in the graph. Vertices will be \n",
    "        {0, 1, 2, ..., n_vertices-1}.\n",
    "    \n",
    "    edges: list(pair(int,int))\n",
    "        Each pair (i,j) in the list denotes an edge between i and j.\n",
    "    \"\"\"\n",
    "    edge_weights = np.full(len(edges), 1, dtype=int)\n",
    "    edges = np.array(edges)\n",
    "    graph = csr_matrix((edge_weights, (edges[:,0], edges[:,1])), shape=(n_vertices, n_vertices))\n",
    "    _ , labels = connected_components(csgraph=graph, directed=False, return_labels=True)\n",
    "    return labels\n",
    "\n",
    "def compute_kde(point_cloud, bandwidth):\n",
    "    \"\"\" Compute a Gaussian kernel density estimator.\n",
    "     \n",
    "    point_cloud: ndarray\n",
    "        An numpy array consisting of points in some Euclidean space.\n",
    "\n",
    "    bandwidth: float\n",
    "        The bandwidth used to compute the KDE\n",
    "    \"\"\"\n",
    "    return gaussian_kde(np.vstack((point_cloud[:,0],point_cloud[:,1])), bandwidth)\n",
    "    \n",
    "def plot_suplevelset(values_on_grid, xmin, xmax, ymin, ymax, grid_granularity_x, grid_granularity_y, contour=False):\n",
    "    xx, yy = np.mgrid[xmin:xmax:grid_granularity_x*1j, ymin:ymax:grid_granularity_y*1j]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    if not contour:\n",
    "        ax.imshow(np.rot90(values_on_grid), cmap='Blues', extent=[xmin, xmax, ymin, ymax])\n",
    "    else:\n",
    "        cset = ax.contour(xx, yy, values_on_grid, colors='k')\n",
    "        ax.clabel(cset, inline=1, fontsize=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples using the functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the connected components of a graph with 4 vertices and 2 edges\n",
    "n_vertices = 4\n",
    "edges = [[0,1],[1,2]]\n",
    "print(graph_connected_components(n_vertices, edges))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a Gaussian KDE and plot it\n",
    "data_blobs = datasets.make_blobs(n_samples=500, n_features=2, random_state=10)[0]\n",
    "plot_clustering(data_blobs)\n",
    "kde = compute_kde(data_blobs, 0.1)\n",
    "\n",
    "xmin = -3\n",
    "xmax = 8\n",
    "ymin = -12\n",
    "ymax = 8\n",
    "grid_granularity_x = 100\n",
    "grid_granularity_y = 100\n",
    "\n",
    "xx, yy = np.mgrid[xmin:xmax:grid_granularity_x*1j, ymin:ymax:grid_granularity_y*1j]\n",
    "grid = np.vstack([xx.ravel(), yy.ravel()])\n",
    "f = np.reshape(kde(grid).T, xx.shape)\n",
    "\n",
    "plot_suplevelset(f, xmin, xmax, ymin, ymax, grid_granularity_x, grid_granularity_y, contour=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A warm up exercise\n",
    "\n",
    "First use your function to cluster the dataset `data_blobs`, defined right above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download table3 from https://cdsarc.cds.unistra.fr/ftp/J/ApJS/194/9/\n",
    "# this contains the main dataset of\n",
    "# \"X-RAY STAR CLUSTERS IN THE CARINA COMPLEX\" Feigelson et al.\n",
    "import requests\n",
    "url = \"https://cdsarc.cds.unistra.fr/ftp/J/ApJS/194/9/table3.dat\"\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "\n",
    "# we now preprocess the data we downloaded. We will consider the subsample\n",
    "# referred to as the \"spatially complete sample\" in section 2 of the paper.\n",
    "# See https://cdsarc.cds.unistra.fr/ftp/J/ApJS/194/9/ReadMe for a description\n",
    "# of the dataset\n",
    "unfiltered_dataset = []\n",
    "large_scale_region = []\n",
    "class_broos = []\n",
    "cluster_feigelson = []\n",
    "photon_flux = []\n",
    "for line in data.split('\\n'):\n",
    "    row = line.split()\n",
    "    if len(row) > 0:\n",
    "        # these are the two spatial coordinates of the data points\n",
    "        unfiltered_dataset.append(row[3:5])\n",
    "        # this quantifies how bright the source is\n",
    "        photon_flux.append(row[6])\n",
    "        # the following contains the label H2 for points that\n",
    "        # are deemed to probably belong to the Carina complex\n",
    "        class_broos.append(row[8])\n",
    "        # this contains the cluster label as reported in the paper\n",
    "        if len(row) == 11 and row[9][0] == \"C\":\n",
    "            cluster_feigelson.append(int(row[9][1:]))\n",
    "        else:\n",
    "            cluster_feigelson.append(-1)\n",
    "unfiltered_dataset = np.array(unfiltered_dataset, dtype=float)\n",
    "cluster_feigelson = np.array(cluster_feigelson, dtype=int)\n",
    "class_broos = np.array(class_broos, dtype=str)\n",
    "photon_flux = np.array(photon_flux, dtype=float)\n",
    "\n",
    "# photon threshold as in the paper\n",
    "photon_flux_threshold = -5.9\n",
    "bright_enough = (photon_flux > photon_flux_threshold)\n",
    "\n",
    "# probable Carina members\n",
    "probable_carina_members = (class_broos == \"H2\")\n",
    "\n",
    "# we put the two conditions together\n",
    "condition = bright_enough & probable_carina_members\n",
    "\n",
    "# we filter the point cloud and the cluster labels using\n",
    "# the two conditions above. So we are only looking for bright sources that\n",
    "# are considered to probably belong to the Carina complex\n",
    "X = unfiltered_dataset[condition]\n",
    "cluster = cluster_feigelson[condition]\n",
    "# print the size of the filtered data.\n",
    "# NOTE: we are getting 2870 samples instead of the 3220 samples reported in\n",
    "# section 2 of the paper. I do not know why this is. If you are interested,\n",
    "# please look into it!\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering reported in the paper.\n",
    "plt.figure(figsize=(5,7))\n",
    "plot_clustering(X, cluster, sizes=[6,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30765f2d388fe69164e90351ba0c946ae17d7e45b97f38e607467fe202d5073e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
